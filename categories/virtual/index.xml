<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>virtual on Goofing Osamu</title>
    <link>/categories/virtual/</link>
    <description>Recent content in virtual on Goofing Osamu</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 12 Feb 2021 00:00:00 +0000</lastBuildDate><atom:link href="/categories/virtual/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>仮想環境(5)</title>
      <link>/jp/2021/02/12/virt-05/</link>
      <pubDate>Fri, 12 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/jp/2021/02/12/virt-05/</guid>
      <description>引き続きLXCの非特権仮想環境周辺を深堀りとして Linux Namespaces を読み解きます。
User Namespaces Linux Namespacesの中でuser_namespaces(7)で説明されている User NamespacesはユーザーIDやグループID等のセキュリティー関連の識別子 と属性(credentials(7)参照。本来は、資格、信任状の意味の単語)を 分離します。属性とは具体的に言うとルートディレクトリーや、 キー(keyrings(7)参照。本来は、鍵の意味の単語)や、 ケーパビリティ(capabilities(7)参照。本来は能力・資質の意味の単語) 等です。
このUser Namespacesにより、Namespacesの中ではあたかも特権ユーザーとして 振る舞いながら、Namespacesの外では通常の非特権ユーザー権限を保持するプロセスを 実現することができます。この際のユーザーIDの対応関係が/proc/[pid]/uid_map ファイルに記されています。(グループIDの場合は/proc/[pid]/gid_map)
たとえばコンテナ環境外のシェルプロセスのuid_map以下です。
$ cat /proc/$$/uid_map 0 0 4294967295 これは、最初の0 が現amespacesのユーザーID、次の0 が(実在しない)親Namespaces のユーザーID に対応し、(2^32)-1の4294967295が対応関係範囲長となります。 対応関係範囲長を2^32としないのは故意で2^32番目のユーザーID 4294967295 は「ユーザーID無し」の返り値となっているからだそうです。
/proc/[pid]/uid_mapは、newuidmap(1)で設定できます。その際に 許容されるユーザーIDが/etc/subuidに羅列し規定されています。
LXC 4.0の非特権ユーザーのコンテナ起動は、/usr/share/doc/lxc/README.Debianに 詳しく書かれています。この様な現在のシステムでは、各コンテナ環境では 16ビットユーザーIDの 0 - 65536＝(2^16)-2 を使っているようです。
$ id -nu osamu $ cat /etc/subuid osamu:100000:65536 ここの100000は見通しが良いように大きい目になっていますが、65538以上の 適当なオフセット値ですね。このようなオフセット値を各コンテナ毎ずらせば 確かにコンテナを安全に隔離できますね。
ちなみに、chroot(2)システムコールが設定するプロセスごとの ルートディレクトリーは/proc/[pid]/rootからのシムリンクとして 記録されています。これを使えば、コンテナ毎に違うルートファイルシステム 内容のシステムを作成できます。
オーバーレイマウントやバインドマウント等のカーネル機能も効率的な仮想環境 構成に使えます。
なんとなく、コンテナ環境の仮想化が収まっている全体感というか様子が、 ちょっと見えてきました。</description>
    </item>
    
    <item>
      <title>仮想環境(4)</title>
      <link>/jp/2021/02/06/virt-04/</link>
      <pubDate>Sat, 06 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>/jp/2021/02/06/virt-04/</guid>
      <description>引き続きLXCの非特権仮想環境周辺を深堀りします。 (2021-Feb Debian Bulleseye/testing pre-11 release)
まあ、非特権LXC実行環境整備の際に出てきた/etc/subuidと/etc/subgidは、 非特権仮想環境内の見かけのUIDやGIDから、親システムのUIDやGIDの への対応関係定義ということは直感的分かりました。
ただ伝統的なUNIXの範疇を越えているので、Linuxのカーネルレベルで どこがどう拡張されているのかを確認しました。
Linux Namespaces どうもLXCも含めた各種コンテナ環境は2002年以降拡充されてきた LinuxのNamespaces というカーネルの機能を使っていることがキーだと分かりました。
とりあえず、以下の関連マンページに目を通しました。
 namespaces(7): LinuxのNamespaces全体の説明 cgroup_namespaces(7): Cgroup root directory ipc_namespaces(7): System V IPC, POSIX message queues network_namespaces(7): Network devices, stacks, ports, etc. mount_namespaces(7): Mount points pid_namespaces(7): Process IDs time_namespaces(7): Boot and monotonic clocks user_namespaces(7): User and group IDs uts_namespaces(7): Hostname and NIS domain name  Cgroup Namespaces Linux Namespacesの中でcgroup_namespaces(7)は、/proc/[pid]/cgroup と /proc/[pid]/mountinfo から見えるプロセスのcgroups (コントロールグループ) の見え方を仮想化します。各種コンテナ環境を可能にする仮想化技術の中心的な要素 としておもしろそうだったので、自分なりに追加の状況確認をしながらtraceしたの ですがマンページの通りには行きませんでした。</description>
    </item>
    
    <item>
      <title>仮想環境(3)</title>
      <link>/jp/2021/01/28/virt-03/</link>
      <pubDate>Thu, 28 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>/jp/2021/01/28/virt-03/</guid>
      <description>引き続きchrootの強化版のようなLXCを使っての仮想環境作成を深堀りします。
LXC仮想環境の停止 仮想環境のカスタマイズした起動をするためには、作成し起動した仮想環境のSTATEを STOPPED(停止)に確実にします。
$ sudo lxc-stop -n sid $ sudo lxc-ls -f NAME STATE AUTOSTART GROUPS IPV4 IPV6 UNPRIVILEGED buster STOPPED 0 - - - false sid STOPPED 0 - - - false LXC仮想環境とのデーター共有起動 仮想環境のカスタマイズした起動時に、設定変数を指定することで、ホスト側の /home/fish/srcを仮想環境内の/home/fishとしてアクセスできるように共有化 された仮想環境として起動できます。この仮想環境環境にユーザーアカウントに ログインするまでの手順は以下です。
$ sudo lxc-start -n sid \ -s &amp;quot;lxc.mount.entry=/home/fish/src home/fish none bind 0 0&amp;quot; $ sudo lxc-attach -n sid root@sid:/# login sid login: fish Password: ... fish@sid:~$ ここで仮想環境内のホームディレクトリーで見えるのは/home/fish/srcと同一デバイス上の ファイルだけです。(再帰的マウントはされません。)
このLXC仮想環境内でパッケージビルドなどをすれば綺麗な環境ででき、さらにその結果に ホスト側から直接アクセスできます。
ここでは、lxc-attach+loginでユーザーアカウントに入っていますが、lxc-consoleを 使っても良いです.</description>
    </item>
    
    <item>
      <title>仮想環境(2)</title>
      <link>/jp/2021/01/08/virt-02/</link>
      <pubDate>Fri, 08 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>/jp/2021/01/08/virt-02/</guid>
      <description>chrootを使ってのデバグ用のsid仮想環境作成をpbuilder/cowbuilderでと言うのは 少々強引です。とはいえ直接chrootやmountコマンドで仮想環境作成というのも 面倒です。
そこで、chrootの強化版のような環境設定インフラが整ったLXCを使ってのパッケージ 作成やデバグ用や古い環境下での動作確認等に使え、システムの立ち上げや動作が 軽快な仮想環境作成を試みます。(KVMは悪くは無いですが、重いことは否めません)
ちなみに、DebianではLXDはまだパッケージされていないので、ここでは裸の LXC 4.0 のインフラを使います。
WEB上のLXCの情報は古い1.0や2.0の情報とか、新規のUIを提供するLXDの情報が多い ので、bulleseyeベースの現行testing環境で基本操作を行って詳細の確認しています。
Debianの最新のLXC環境を確認するには、まず/usr/share/doc/lxc/README.Debianを しっかり読む必要があります。ここに書かれたユーザー権限で実行されるコンテナ (unprivileged containers) 関連の手動設定は重要です。
まずは、簡単なROOT権限で実行されるコンテナ中心に始めます。
LXC仮想環境作成 LXCを使ってのパッケージ作成やデバグ用等に使うsid環境の仮想環境作成を試みます。
 $ sudo lxc-create -n sid -t debian -- -r sid もし、ミラーが不調なら、安定そうなUSミラーを使います。
 $ sudo lxc-create -n sid -t debian -- -r sid --mirror=http://ftp.us.debian.org 意外と簡単です。これで、/var/lib/lxc/sid/が作成されます。この中に、sidコンテナ 環境のファイルシステムがrootfsディレクトリー以下に、またそのコンテナ環境の設定 ファイルconfig が作成されています。
コンテナ環境のファイルシステム:
 # root@goofy:/var/lib/lxc/sid# tree -L 2 -F . ├── config └── rootfs/ ├── bin -&amp;gt; usr/bin/ ├── boot/ ├── dev/ ├── etc/ ├── home/ ├── lib -&amp;gt; usr/lib/ ├── lib32 -&amp;gt; usr/lib32/ ├── lib64 -&amp;gt; usr/lib64/ ├── libx32 -&amp;gt; usr/libx32/ ├── media/ ├── mnt/ ├── opt/ ├── proc/ ├── root/ ├── run/ ├── sbin -&amp;gt; usr/sbin/ ├── selinux/ ├── srv/ ├── sys/ ├── tmp/ ├── usr/ └── var/ コンテナ環境の設定ファイルconfig:</description>
    </item>
    
    <item>
      <title>仮想環境(1)</title>
      <link>/jp/2020/12/13/virt-01/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>/jp/2020/12/13/virt-01/</guid>
      <description>開発環境の基本 開発環境は、できるだけ安定しているほうがストレスが少ないです。editorを 使いメールやウエッブページを読むだけならstable環境が使えればそれでも いいのですが、新しいハードウエアー (Thinkpad T14, AMD Ryzen 5 PRO 4650U with Radeon Graphics)だとグラフィクスドライバーの問題があるので testing ぐらいは必要です。でも歳々アップデートすると不安定になったりして面倒です。
パッケージ作成環境 一方、通常のパッケージ作成には、確実に sid/unstable 環境とするために pbuilder/cowbuilder を使って 設定 された仮想化された chroot環境 を使っています。(確かに、schroot/sbuild 系の方が良い面はあるのでしょうが、 これは私の惰性による選択です。) 開発環境をsidにしなくてもパッケージが正しいsid環境 で作成でき快適です。
直接chrootコマンドを用いると、必要なファイルシステムを仮想環境からアクセス出来るよう にするための操作が煩雑になりますが、pbuilder系等のコマンドを用いるとこれらの 連動する付帯操作や作業用の使い捨てシステムの作成を自動的にしてくれるので便利です。
デバグ用の仮想環境作成 (chroot) なるべくメインのシステムを変えずにデバグを効率的にするために、 いくつかのパッケージがインストールされたデバグ用の仮想化されたchroot環境を 上記の延長線上で準備しました。こっちは、使い捨て環境と言うより使いまわし 環境といった感じです。
cowbuilder を使って、~/wip以下にchrootの開発環境を作成します。
 $ sudo cowbuilder create --basepath ~/wip ... $ sudo cowbuilder login --basepath ~/wip ... root@goofy:/# apt-get install git vim mc aptitude devscripts iproute2 ... root@goofy:/# ^D 後は、この環境に以下で使う度にログインして、root環境で各種コマンドを使います。
 $ sudo cowbuilder login --basepath ~/wip .</description>
    </item>
    
  </channel>
</rss>
